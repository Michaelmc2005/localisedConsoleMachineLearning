import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np

filename = "posSent.txt"
with open(filename, "r") as file:
    positive_words = [line.rstrip() for line in file.readlines()]

filename2 = "negSent.txt"
with open(filename2, "r") as file:
    negative_words = [line.rstrip() for line in file.readlines()]

filename3 = "neutralSent.txt"
with open(filename3, "r") as file:
    neutral_words = [line.rstrip() for line in file.readlines()]

positive_labels = [1] * len(positive_words)
negative_labels = [0] * len(negative_words)
neutral_labels = [2] * len(neutral_words)

sentences = positive_words + negative_words + neutral_words
labels = positive_labels + negative_labels + neutral_labels


tokenizer = Tokenizer(num_words=10000, oov_token="<OOV>")
tokenizer.fit_on_texts(sentences)
word_index = tokenizer.word_index

max_length = 20

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(10000, 16, input_length=max_length),
    tf.keras.layers.GlobalAveragePooling1D(),
    tf.keras.layers.Dense(3, activation='softmax')
])

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

num_epochs = 500
labels = np.array(labels) 
sequences = tokenizer.texts_to_sequences(sentences)
padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')
model.fit(padded_sequences, labels, epochs=num_epochs)

while True:
    input_text = input("Enter a sentence to analyze sentiment: ")
    input_sequence = tokenizer.texts_to_sequences([input_text])
    input_padded_sequence = pad_sequences(input_sequence, maxlen=max_length, padding='post', truncating='post')
    prediction = model.predict(input_padded_sequence)[0]
    predicted_label = np.argmax(prediction)
    if predicted_label == 0:
        print(f"'{input_text}' is negative")
    elif predicted_label == 1:
        print(f"'{input_text}' is positive")
    else:
        print(f"'{input_text}' is neutral")
    check = str
    check = input("Did the model predict correctly? (y/n): ")
    if check == "n":
      if predicted_label == 0 or predicted_label == 1 or predicted_label == 2:
          correct_label = input(f"Enter 0 for negative, 1 for positive, or 2 for neutral: ")
          if correct_label == '0':
              predicted_label = 0
          elif correct_label == '1':
              predicted_label = 1
          elif correct_label == '2':
              predicted_label = 2
          else:
              print("Invalid input, defaulting to neutral")
              predicted_label = 2
      if predicted_label == 0:
          with open('negSent.txt', 'a') as f:
              f.write('\n' + input_text)
              filename = "posSent.txt"
          with open(filename, "r") as file:
              positive_words = [line.rstrip() for line in file.readlines()]

          filename2 = "negSent.txt"
          with open(filename2, "r") as file:
              negative_words = [line.rstrip() for line in file.readlines()]

          filename3 = "neutralSent.txt"
          with open(filename3, "r") as file:
              neutral_words = [line.rstrip() for line in file.readlines()]

          positive_labels = [1] * len(positive_words)
          negative_labels = [0] * len(negative_words)
          neutral_labels = [2] * len(neutral_words)

          sentences = positive_words + negative_words + neutral_words
          labels = positive_labels + negative_labels + neutral_labels

          tokenizer = Tokenizer(num_words=10000, oov_token="<OOV>")
          tokenizer.fit_on_texts(sentences)
          word_index = tokenizer.word_index

          max_length = 20

          model = tf.keras.Sequential([
              tf.keras.layers.Embedding(10000, 16, input_length=max_length),
              tf.keras.layers.GlobalAveragePooling1D(),
              tf.keras.layers.Dense(3, activation='softmax')
          ])

          model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

          num_epochs = 150
          labels = np.array(labels) 
          sequences = tokenizer.texts_to_sequences(sentences)
          padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')
          model.fit(padded_sequences, labels, epochs=num_epochs)
      elif predicted_label == 1:
          with open('posSent.txt', 'a') as f:
              f.write('\n' + input_text)
          filename = "posSent.txt"
          with open(filename, "r") as file:
              positive_words = [line.rstrip() for line in file.readlines()]

          filename2 = "negSent.txt"
          with open(filename2, "r") as file:
              negative_words = [line.rstrip() for line in file.readlines()]

          filename3 = "neutralSent.txt"
          with open(filename3, "r") as file:
              neutral_words = [line.rstrip() for line in file.readlines()]

          positive_labels = [1] * len(positive_words)
          negative_labels = [0] * len(negative_words)
          neutral_labels = [2] * len(neutral_words)

          sentences = positive_words + negative_words + neutral_words
          labels = positive_labels + negative_labels + neutral_labels

          tokenizer = Tokenizer(num_words=10000, oov_token="<OOV>")
          tokenizer.fit_on_texts(sentences)
          word_index = tokenizer.word_index

          max_length = 20

          model = tf.keras.Sequential([
              tf.keras.layers.Embedding(10000, 16, input_length=max_length),
              tf.keras.layers.GlobalAveragePooling1D(),
              tf.keras.layers.Dense(3, activation='softmax')
          ])

          model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

          num_epochs = 150
          labels = np.array(labels) 
          sequences = tokenizer.texts_to_sequences(sentences)
          padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')
          model.fit(padded_sequences, labels, epochs=num_epochs)
      else:
          with open('neutralSent.txt', 'a') as f:
              f.write('\n' + input_text)
          filename = "posSent.txt"
          with open(filename, "r") as file:
              positive_words = [line.rstrip() for line in file.readlines()]

          filename2 = "negSent.txt"
          with open(filename2, "r") as file:
              negative_words = [line.rstrip() for line in file.readlines()]

          filename3 = "neutralSent.txt"
          with open(filename3, "r") as file:
              neutral_words = [line.rstrip() for line in file.readlines()]

          positive_labels = [1] * len(positive_words)
          negative_labels = [0] * len(negative_words)
          neutral_labels = [2] * len(neutral_words)

          sentences = positive_words + negative_words + neutral_words
          labels = positive_labels + negative_labels + neutral_labels

          tokenizer = Tokenizer(num_words=10000, oov_token="<OOV>")
          tokenizer.fit_on_texts(sentences)
          word_index = tokenizer.word_index

          max_length = 20

          model = tf.keras.Sequential([
              tf.keras.layers.Embedding(10000, 16, input_length=max_length),
              tf.keras.layers.GlobalAveragePooling1D(),
              tf.keras.layers.Dense(3, activation='softmax')
          ])

          model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

          num_epochs = 150
          labels = np.array(labels) 
          sequences = tokenizer.texts_to_sequences(sentences)
          padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')
          model.fit(padded_sequences, labels, epochs=num_epochs)
    else:
      print("Thank you for your feedback")